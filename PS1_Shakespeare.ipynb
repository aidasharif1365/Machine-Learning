{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of PS1-Shakespeare.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aidasharif1365/Machine-Learning/blob/main/PS1_Shakespeare.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghmXbcymaHxC"
      },
      "source": [
        "In this experiment, you will train models to distringuish examples of two different genres of Shakespeare's plays: comedies and tragedies. (We'll ignore the histories, sonnets, etc.) Since he died four hundred years ago, Shakespeare has not written any more plays—although scraps of various other works have come to light. We are not, therefore, interested in building models simply to help categorize an unbounded stream of future documents, as we might be in other applications of text classification; rather, we are interested in what a classifier might have to tell us about what we mean by the terms “comedy” and “tragedy”.\n",
        "\n",
        "You will start by copying and running your `createBasicFeatures` function from the experiment with movie reviews. Do the features the classifier focuses on tell you much about comedy and tragedy in general?\n",
        "\n",
        "You will then implement another featurization function `createInterestingFeatures`, which will focus on only those features you think are informative for distinguishing between comedy and tragedy. Accuracy on leave-one-out cross-validation may go up, but it more important to look at the features given the highest weight by the classifier. Interpretability in machine learning, of course, may be harder to define than accuracy—although accuracy at some tasks such as summarization is hard enoough."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdVS67_HNRmW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9eb70d9-f0c1-4ae3-9b84-21ae37405d55"
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "import json\n",
        "import spacy\n",
        "import string\n",
        "import requests\n",
        "import collections\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_validate,LeaveOneOut,KFold\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer,TfidfTransformer\n",
        "from spacy.lang.en import English\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.stem import PorterStemmer,WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzjMY8fYQbB6"
      },
      "source": [
        "#read in the shakespeare corpus\n",
        "def readShakespeare():\n",
        "  raw = requests.get(\"https://raw.githubusercontent.com/mutherr/CS6120-PS1-data/master/shakespeare_plays.json\").text.strip()\n",
        "  corpus = [json.loads(line) for line in raw.split(\"\\n\")]\n",
        "\n",
        "  #remove histories from the data, as we're only working with tragedies and comedies\n",
        "  corpus = [entry for entry in corpus if entry[\"genre\"] != \"history\"]\n",
        "  return corpus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eO4U7LUzi3on"
      },
      "source": [
        "def stemSentence(sentence):\n",
        "    porter = PorterStemmer()\n",
        "    token_words=word_tokenize(sentence)\n",
        "    stem_sentence=[]\n",
        "    for word in token_words:\n",
        "        stem_sentence.append(porter.stem(word))\n",
        "        stem_sentence.append(\" \")\n",
        "    return \"\".join(stem_sentence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7tl8RxIyRec"
      },
      "source": [
        "def lemmaSentence(sentence):\n",
        "  wordnet_lemmatizer = WordNetLemmatizer()\n",
        "  token_words=word_tokenize(sentence)\n",
        "  lemma_sentence=[]\n",
        "  for word in token_words:\n",
        "      lemma_sentence.append(wordnet_lemmatizer.lemmatize(word))\n",
        "      lemma_sentence.append(\" \")\n",
        "  return \"\".join(lemma_sentence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7dajWAZsImK"
      },
      "source": [
        "def remove_stopwords(sentence,stopwords_dict):\n",
        "  punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
        "  #punctuations=''\n",
        "  no_punct = \"\"\n",
        "  token_words=word_tokenize(sentence)\n",
        "  no_stop=' '.join([word for word in token_words if word not in stopwords_dict])\n",
        "\n",
        "  for char in no_stop:\n",
        "    if char not in punctuations:\n",
        "        no_punct = no_punct + char\n",
        "  return no_punct"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0r3oL3TdHIU"
      },
      "source": [
        "This is where you will implement two functions to featurize the data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "039fPQcF7OkN"
      },
      "source": [
        "#NB: The current contents are for testing only\n",
        "#This function should return: \n",
        "#  -a sparse numpy matrix of document features\n",
        "#  -a list of the correct genre for each document\n",
        "#  -a list of the vocabulary used by the features, such that the ith term of the\n",
        "#    list is the word whose counts appear in the ith column of the matrix. \n",
        "\n",
        "# This function should create a feature representation using all tokens that\n",
        "# contain an alphabetic character.\n",
        "def createBasicFeatures(corpus):\n",
        "  texts=[]\n",
        "  vocab=[]\n",
        "  classes=[]\n",
        "\n",
        "  for i in range(len(corpus)):\n",
        "    texts.append(corpus[i][\"text\"])\n",
        "    classes.append(corpus[i][\"genre\"])\n",
        "    \n",
        "  #using countvectorizer to count words in documents\n",
        "  one_hot_vectorizer = CountVectorizer()\n",
        "  one_hot_matrix = one_hot_vectorizer.fit_transform(texts)\n",
        "  vocab_dict = (one_hot_vectorizer.vocabulary_)\n",
        "\n",
        "  for k in vocab_dict:\n",
        "    vocab.append(k)\n",
        "\n",
        "  return one_hot_matrix,classes,vocab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nwv8un0TjmRg",
        "outputId": "9855fdfa-4697-4a5c-a930-7ebf9004486e"
      },
      "source": [
        "corpus = readShakespeare()\n",
        "X,y,vocab = createBasicFeatures(corpus)\n",
        "runEvaluation(X, y, vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------L1 Norm-----------\n",
            "The model's average accuracy is 0.769231\n",
            "The most informative terms for pos are: ['pounds', 'gums', 'minimus', 'elevated', 'rogero', 'mountebanks', 'rests', 'immoment', 'unspoke', 'wrist', 'couplement', 'guerra', 'fortuna', 'whereuntil', 'parfect', 'arinado', 'pursents', 'vara', 'career', 'jesting']\n",
            "The most informative terms for neg are: ['beaks', 'cautelous', 'lading', 'brood', 'bemete', 'stubble', 'corse', 'vox', 'deserves', 'glowing', 'ber', 'simile', 'arinado', 'couplement', 'guerra', 'whereuntil', 'pompion', 'parfect', 'pursents', 'vara']\n",
            "----------L2 Norm-----------\n",
            "The model's average accuracy is 0.730769\n",
            "The most informative terms for pos are: ['rogero', 'gums', 'immoment', 'pounds', 'braving', 'rests', 'mountebanks', 'elevated', 'minimus', 'new', 'disarm', 'accompanied', 'goosequills', 'repeals', 'partially', 'despiseth', 'clad', 'hears', 'alexander', 'wrist']\n",
            "The most informative terms for neg are: ['stubble', 'brood', 'cautelous', 'beaks', 'stonecutter', 'vox', 'glowing', 'ber', 'corse', 'deserves', 'lading', 'avenged', 'ivory', 'maidenhood', 'bemete', 'crowns', 'wid', 'simile', 'insinuateth', 'reapers']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mM9dJSE2_OVt"
      },
      "source": [
        "#checkinng the most used words in pos and neg classes to make the stopword list\n",
        "pos_dict=collections.defaultdict(lambda:0)\n",
        "neg_dict=collections.defaultdict(lambda:0)\n",
        "\n",
        "for i in range(len(corpus)):\n",
        "  sentence=(corpus[i][\"text\"])\n",
        "  token_words=word_tokenize(sentence)\n",
        "  if corpus[i][\"genre\"]=='comedy':\n",
        "    for word in token_words:\n",
        "      pos_dict[word]=pos_dict[word]+1\n",
        "  elif corpus[i][\"genre\"]=='tragedy': \n",
        "    for word in token_words:\n",
        "      neg_dict[word]=neg_dict[word]+1\n",
        "        \n",
        "      \n",
        "pos_dict={k:v for k,v in sorted(pos_dict.items(), key=lambda item:item[1],reverse=True)}\n",
        "neg_dict={k:v for k,v in sorted(neg_dict.items(), key=lambda item:item[1],reverse=True)}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 655
        },
        "id": "oUyNHyf5_2Zp",
        "outputId": "86263a09-a194-4a28-cc71-82b6b6f1fce2"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig1 = plt.figure()\n",
        "fig2 = plt.figure()\n",
        "ax1 = fig1.add_axes([0,0,1,1])\n",
        "ax2 = fig2.add_axes([0,0,1,1])\n",
        "freqPos = []\n",
        "wordsPos = []\n",
        "freqNeg = []\n",
        "wordsNeg = []\n",
        "\n",
        "limit=23\n",
        "for k in neg_dict:\n",
        "  if limit>0:\n",
        "    wordsNeg.append(k)\n",
        "    freqNeg.append(neg_dict[k])\n",
        "  limit-=1\n",
        "\n",
        "limit=23\n",
        "for k in pos_dict:\n",
        "  if limit>0:\n",
        "    wordsPos.append(k)\n",
        "    freqPos.append(pos_dict[k])\n",
        "  limit-=1\n",
        "\n",
        "ax2.bar(wordsNeg,freqNeg)\n",
        "ax1.bar(wordsPos,freqPos)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bH8pcqudM9i5"
      },
      "source": [
        "words=['the', 'and','i','of','my','is','a','he','his','for','d','with']\n",
        "stopwords_dict=dict.fromkeys(words,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgNVhn8KjAe7"
      },
      "source": [
        "# This function can add other features you want that help classification\n",
        "# accuracy, such as bigrams, word prefixes and suffixes, etc.\n",
        "#it stems, lemmatizes, removes stopwords, sets thresholds of min and max number\n",
        "#of words in Countervectorizer, uses ngrams\n",
        "#each feature changer could be turned on or off\n",
        "def createInterestingFeatures(corpus,stopword,stem,lemma,ngram,mindf,maxdf):\n",
        "  raw=[]\n",
        "  vocab=[]\n",
        "  classes=[]\n",
        "\n",
        "  #based on the feature changer options this loops implements different parts\n",
        "  for i in range(len(corpus)):\n",
        "    sentence=(corpus[i][\"text\"])\n",
        "    if stopword:\n",
        "      sentence=remove_stopwords(sentence,stopwords_dict)\n",
        "    if stem:\n",
        "      sentence=stemSentence(sentence)\n",
        "    if lemma: \n",
        "      sentence=lemmaSentence(sentence)\n",
        "    raw.append(sentence)\n",
        "    classes.append(corpus[i][\"genre\"])\n",
        "\n",
        "  #setting ngrams, min_df and max_df in Countervectorizer\n",
        "  vectorizer = CountVectorizer(ngram_range=ngram,min_df=mindf,max_df=maxdf) \n",
        "  #fitting the vectorizer\n",
        "  ngram_matrix = vectorizer.fit_transform(raw)\n",
        "  vocab_dict = (vectorizer.vocabulary_)\n",
        "\n",
        "  for k in vocab_dict:\n",
        "    vocab.append(k)\n",
        "\n",
        "  return ngram_matrix,classes,vocab\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GAcz03W6zIA"
      },
      "source": [
        "Best result:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGqXxkfL6xgn",
        "outputId": "64ab4943-f362-4113-bba6-fe5ecf5355a5"
      },
      "source": [
        "words=['the', 'and','i','of','my','is','a','he','his','for','d','with']\n",
        "stopwords_dict=dict.fromkeys(words,1)\n",
        "X,y,vocab = createInterestingFeatures(corpus,stopword=False,stem=False,lemma=False,ngram=(0,3),mindf=3,maxdf=2200)\n",
        "runEvaluation(X, y, vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------L1 Norm-----------\n",
            "The model's average accuracy is 0.884615\n",
            "The most informative terms for pos are: ['think for', 'between this', 'me hear', 'do love my', 'not here', 'needful', 'with us to', 'his mind', 'exit duke', 'you do remember', 'the heart to', 'and through the', 'you my good', 'all and leave', 'you have little', 'them to you', 'you think you', 'are at the', 'you have you', 'you where he']\n",
            "The most informative terms for neg are: ['pompey pompey', 'were such', 'me with patience', 'will by', '', 'on the way', 'an please you', 'when all the', 'which ne er', 'you have little', 'you do remember', 'the heart to', 'you my good', 'of all and', 'all and leave', 'them to you', 'you think you', 'are at the', 'you have you', 'you where he']\n",
            "----------L2 Norm-----------\n",
            "The model's average accuracy is 0.730769\n",
            "The most informative terms for pos are: ['think for', 'me hear', 'needful', 'do love my', 'with us to', 'between this', 'exit duke', 'not here', 'behold my', 'his mind', 'lady she is', 'no maiden', 'shall not', 'than he is', 'not by the', 'for ladies', 'that is', 'will endure', 'here lie', 'destin']\n",
            "The most informative terms for neg are: ['pompey pompey', 'were such', 'it shall not', 'brought to', 'tent and', 'pay your', 'what haste', 'will by', 'shall desire', 'youth and', 'the third', 'custom', 'to sleep', 'did need', 'thee like', 'them and the', 'would change', 'almost with', 'of him that', 'animal']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vv9qhfl1JJsM",
        "outputId": "ee094985-1b35-4b1e-d67c-12d8991ea704"
      },
      "source": [
        "X,y,vocab = createInterestingFeatures(corpus,stopword=False,stem=True,lemma=True,ngram=(0,3),mindf=3,maxdf=2200)\n",
        "runEvaluation(X, y, vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------L1 Norm-----------\n",
            "The model's average accuracy is 0.846154\n",
            "The most informative terms for pos are: ['horn in', 'befor thee', 'wa to', 'he had no', 'fear thi', 'time good', 'is now the', 'should pay', 'fool fool', 'they say there', 'thousand of these', 'beseech you what', 'to break the', 'them on the', 'am glad on', 'true that you', 'to sin in', 'thou shalt see', 'me onc more', 'your compani to']\n",
            "The most informative terms for neg are: ['with much', 'were such', 'hath not yet', 'thi state', '', 'with bloodi', 'keep you in', 'they say they', 'stand not in', 'they say there', 'thousand of these', 'love than', 'beseech you what', 'of the citi', 'to break the', 'am glad on', 'true that you', 'to sin in', 'thou shalt see', 'me onc more']\n",
            "----------L2 Norm-----------\n",
            "The model's average accuracy is 0.692308\n",
            "The most informative terms for pos are: ['horn in', 'wa to', 'time good', 'he had no', 'befor thee', 'is now the', 'fool fool', 'fear thi', 'fan and', 'should pay', 'thou dost and', 'iv scene', 'and not have', 'come my', 'you love your', 'bring in', 'chang their', 'thi fool', 'more honour', 'you still']\n",
            "The most informative terms for neg are: ['with much', 'were such', 'rememb me', 'myself for', 'govern by', 'pack of', 'farewel till', 'thi state', 'give over', 'the beam', 'of feast', 'hard by', 'out of my', 'yield your', 'in scorn', 'th hand', 'me up in', 'that fled', 'way let', 'tell him thi']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nV5MpJri7WAN",
        "outputId": "afd04ec1-44eb-4cb5-d3d2-9fef717d3853"
      },
      "source": [
        "X,y,vocab = createInterestingFeatures(corpus,stopword=True,stem=True,lemma=True,ngram=(1,3),mindf=2,maxdf=2000)\n",
        "runEvaluation(X, y, vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------L1 Norm-----------\n",
            "The model's average accuracy is 0.807692\n",
            "The most informative terms for pos are: ['lord can', 'yet some', 'her knee', 'guess at', 'wors for me', 'thousand death would', 'craft', 'sweep', 'do our', 'womanish', 'menac', 'climat', 'prodigi', 'knotti', 'ghastli', 'stoni', 'unfirm', 'howev', 'tomorrow', 'shriek']\n",
            "The most informative terms for neg are: ['for lord', 'll sauc', 'rome antoni', 'in king', 'but we are', 'had but one', 'for most part', 'like hi', 'to fli', 'to market', 'knotti', 'ghastli', 'unfirm', 'retent', 'prodigi', 'howev', 'climat', 'menac', 'womanish', 'stoni']\n",
            "----------L2 Norm-----------\n",
            "The model's average accuracy is 0.730769\n",
            "The most informative terms for pos are: ['wors for me', 'do our', 'her knee', 'lord can', 'craft', 'guess at', 'yet some', 'sweep', 'further into', 'thousand death would', 'like poison', 'gentleman to', 'princ that', 'thi stori', 'arraign', 'though he', 'late have', 'second gentleman ti', 'scar', 'duti which']\n",
            "The most informative terms for neg are: ['ll sauc', 'for lord', 'but we are', 'rome antoni', 'for most part', 'friend let', 'good friar', 'in king', 'to market', 'anoth door', 'sorri now', 'to fli', 'heard say', 'had but one', 'both part', 'hath banish', 'it possibl', 'but their', 'disarm', 'wife first']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juWHunp12PJD",
        "outputId": "c78e0489-b80c-4f8f-d710-b92a81071f18"
      },
      "source": [
        "X,y,vocab = createInterestingFeatures(corpus,stopword=True,stem=True,lemma=True,ngram=(1,3),mindf=3,maxdf=2200)\n",
        "runEvaluation(X, y, vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------L1 Norm-----------\n",
            "The model's average accuracy is 0.884615\n",
            "The most informative terms for pos are: ['whom thou', 'to be command', 'speech will', 'sovereignti', 'myself will', 'you swear', 'cur in', 'lord exeunt', 'here therefor', 'suit that', 'them while', 'thi we', 'in either', 'all', 'all hail', 'peac thou', 'such name', 'dogg with', 'either side', 'honour no']\n",
            "The most informative terms for neg are: ['face but', 'true he', 'if he love', 'love day', 'almost come', 'no marvel', 'hand who', 'have sat', 'thu if', 'therebi to', 'honour no', 'all', 'thi we', 'in either', 'either side', 'all hail', 'peac thou', 'such name', 'suit that', 'them while']\n",
            "----------L2 Norm-----------\n",
            "The model's average accuracy is 0.730769\n",
            "The most informative terms for pos are: ['myself will', 'whom thou', 'here therefor', 'sovereignti', 'to be command', 'you swear', 'speech will', 'lord exeunt', 'cur in', 'run by', 'make an', 'give way to', 'have kept', 'yet though', 'boy hath', 'find thi', 'impress', 'yet kind', 'part forest', 'come love']\n",
            "The most informative terms for neg are: ['face but', 'love day', 'true he', 'if he love', 'much more', 'no marvel', 'your sword', 'tell who', 'now what news', 'hand who', 'prove thi', 'thou are', 'what thou hast', 'not stay behind', 'not show', 'almost come', 'more such', 'do much', 'hour in', 'would grow']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96v8iJt93UxJ",
        "outputId": "754c3016-b724-4c7b-af51-d15f7bfaa641"
      },
      "source": [
        "X,y,vocab = createInterestingFeatures(corpus,stopword=True,stem=True,lemma=True,ngram=(1,3),mindf=3,maxdf=2200)\n",
        "runEvaluation(X, y, vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------L1 Norm-----------\n",
            "The model's average accuracy is 0.846154\n",
            "The most informative terms for pos are: ['whom thou', 'speech will', 'to be command', 'sovereignti', 'myself will', 'cur in', 'you swear', 'lord exeunt', 'here therefor', 'suit that', 'them while', 'thi we', 'in either', 'all', 'all hail', 'peac thou', 'such name', 'dogg with', 'either side', 'honour no']\n",
            "The most informative terms for neg are: ['face but', 'true he', 'if he love', 'love day', 'almost come', 'no marvel', 'hand who', 'have sat', 'thu if', 'therebi to', 'honour no', 'all', 'thi we', 'in either', 'either side', 'all hail', 'peac thou', 'such name', 'suit that', 'them while']\n",
            "----------L2 Norm-----------\n",
            "The model's average accuracy is 0.730769\n",
            "The most informative terms for pos are: ['myself will', 'whom thou', 'here therefor', 'sovereignti', 'to be command', 'you swear', 'speech will', 'lord exeunt', 'cur in', 'run by', 'make an', 'give way to', 'have kept', 'yet though', 'boy hath', 'find thi', 'impress', 'yet kind', 'part forest', 'come love']\n",
            "The most informative terms for neg are: ['face but', 'love day', 'true he', 'if he love', 'much more', 'no marvel', 'your sword', 'tell who', 'now what news', 'hand who', 'prove thi', 'thou are', 'what thou hast', 'not stay behind', 'not show', 'almost come', 'more such', 'do much', 'hour in', 'would grow']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kz3i2UOkJem9",
        "outputId": "e82b2113-d965-475a-e2ed-3828efcbbd53"
      },
      "source": [
        "X,y,vocab = createInterestingFeatures(corpus,stopword=False,stem=False,lemma=True,ngram=(0,3),mindf=3,maxdf=2200)\n",
        "runEvaluation(X, y, vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------L1 Norm-----------\n",
            "The model's average accuracy is 0.807692\n",
            "The most informative terms for pos are: ['sleep come', 'you wot', 'space for', 'ruin of the', 'grace is', 'patch', 'shall be so', 'not get', 'out my', 'he turn', 'life did', 'is thus', 'your loyal', 'servant or', 'endure your', 'bear from', 'am struck', 'with sorrow', 'this city', 'the injury']\n",
            "The most informative terms for neg are: ['have mind', 'boy son', 'there an end', 'you set', '', 'all and leave', 'lord thou', 'done deed', 'not upon', 'put up', 'know in', 'which this', 'man life', 'noble master', 'life did', 'your loyal', 'loyal servant', 'servant or', 'endure your', 'bear from']\n",
            "----------L2 Norm-----------\n",
            "The model's average accuracy is 0.692308\n",
            "The most informative terms for pos are: ['sleep come', 'space for', 'patch', 'ruin of the', 'shall be so', 'you wot', 'out my', 'grace is', 'say or', 'not get', 'up say', 'act iv', 'do assure', 'can not think', 'love be not', 'father so', 'stay here', 'would not wish', 'the bare', 'the head of']\n",
            "The most informative terms for neg are: ['have mind', 'boy son', 'father if', 'of wine', 'll bear', 'blow them', 'his case', 'you set', 'they lie', 'her mistress', 'yet am', 'with all my', 'first sight', 'which first', 'freedom of', 'son is', 'voice and', 'to myself but', 'go see your', 'mean you sir']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DFnD1lZ3hhy",
        "outputId": "37b1bfad-98d4-40c1-a41b-181c1d96feb6"
      },
      "source": [
        "X,y,vocab = createInterestingFeatures(corpus,stopword=False,stem=False,lemma=False,ngram=(1,2),mindf=3,maxdf=2200)\n",
        "runEvaluation(X, y, vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------L1 Norm-----------\n",
            "The model's average accuracy is 0.846154\n",
            "The most informative terms for pos are: ['leagues off', 'trouble the', 'cannot call', 'you back', 'you came', 'offence', 'scanted', 'they meet', 'you was', 'and heard', 'other will', 'am half', 'than fool', 'for truth', 'things should', 'do appear', 'should stand', 'why in', 'which first', 'crave the']\n",
            "The most informative terms for neg are: ['he on', 'but teach', 'be fortunate', 'are and', 'should stand', 'do appear', 'things should', 'for truth', 'than fool', 'other will', 'why in', 'and heard', 'many things', 'some more', 'go without', 'am half', 'which first', 'well', 'him joy', 'voices and']\n",
            "----------L2 Norm-----------\n",
            "The model's average accuracy is 0.692308\n",
            "The most informative terms for pos are: ['leagues off', 'cannot call', 'offence', 'you came', 'they meet', 'trouble the', 'than am', 'you back', 'am able', 'scanted', 'borne to', 'do nothing', 'towards him', 'and went', 'to thee', 'when thy', 'like dog', 'them it', 'bounds', 'imposition']\n",
            "The most informative terms for neg are: ['he on', 'but teach', 'the porter', 'are full', 'servant you', 'name it', 'recall', 'are and', 'pine and', 'griefs and', 'be fortunate', 'twelvemonth', 'are wise', 'thee go', 'stays', 'my sides', 'with messenger', 'nature so', 'dotes', 'for heaven']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjjIsY513wQC",
        "outputId": "4b902a19-1240-47a3-8e6e-65b57f5865dc"
      },
      "source": [
        "X,y,vocab = createInterestingFeatures(corpus,stopword=False,stem=False,lemma=False,ngram=(0,3),mindf=3,maxdf=2200)\n",
        "runEvaluation(X, y, vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------L1 Norm-----------\n",
            "The model's average accuracy is 0.846154\n",
            "The most informative terms for pos are: ['me hear', 'think for', 'between this', 'do love my', 'needful', 'not here', 'with us to', 'his mind', 'behold my', 'exit duke', 'you do remember', 'the heart to', 'and through the', 'you my good', 'them to you', 'all and leave', 'you think you', 'are at the', 'you have you', 'you where he']\n",
            "The most informative terms for neg are: ['pompey pompey', 'were such', 'brought to', 'me with patience', 'will by', '', 'what haste', 'all and leave', 'you my good', 'and through the', 'the heart to', 'may as well', 'you do remember', 'you have little', 'them to you', 'which ne er', 'you think you', 'when all the', 'an please you', 'on the way']\n",
            "----------L2 Norm-----------\n",
            "The model's average accuracy is 0.730769\n",
            "The most informative terms for pos are: ['think for', 'me hear', 'needful', 'do love my', 'with us to', 'between this', 'exit duke', 'not here', 'behold my', 'his mind', 'lady she is', 'no maiden', 'shall not', 'than he is', 'not by the', 'for ladies', 'that is', 'will endure', 'here lie', 'destin']\n",
            "The most informative terms for neg are: ['pompey pompey', 'were such', 'it shall not', 'brought to', 'tent and', 'pay your', 'what haste', 'will by', 'shall desire', 'youth and', 'the third', 'custom', 'to sleep', 'did need', 'thee like', 'them and the', 'would change', 'almost with', 'of him that', 'animal']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6UHsOMbBEXW",
        "outputId": "416da6a3-5d44-4004-9ac8-b0cd9c3c518b"
      },
      "source": [
        "words=['the', 'and','i','of','my','is','a','he','his','for','d','with']\n",
        "stopwords_dict=dict.fromkeys(words,1)\n",
        "X,y,vocab = createInterestingFeatures(corpus,stopword=False,stem=False,lemma=False,ngram=(0,3),mindf=3,maxdf=2400)\n",
        "runEvaluation(X, y, vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------L1 Norm-----------\n",
            "The model's average accuracy is 0.884615\n",
            "The most informative terms for pos are: ['think for', 'between this', 'me hear', 'do love my', 'not here', 'needful', 'with us to', 'his mind', 'exit duke', 'you do remember', 'the heart to', 'and through the', 'you my good', 'all and leave', 'you have little', 'them to you', 'you think you', 'are at the', 'you have you', 'you where he']\n",
            "The most informative terms for neg are: ['pompey pompey', 'were such', 'me with patience', 'will by', '', 'on the way', 'an please you', 'when all the', 'which ne er', 'you have little', 'you do remember', 'the heart to', 'you my good', 'of all and', 'all and leave', 'them to you', 'you think you', 'are at the', 'you have you', 'you where he']\n",
            "----------L2 Norm-----------\n",
            "The model's average accuracy is 0.730769\n",
            "The most informative terms for pos are: ['think for', 'me hear', 'needful', 'do love my', 'with us to', 'between this', 'exit duke', 'not here', 'behold my', 'his mind', 'lady she is', 'no maiden', 'shall not', 'than he is', 'not by the', 'for ladies', 'that is', 'will endure', 'here lie', 'destin']\n",
            "The most informative terms for neg are: ['pompey pompey', 'were such', 'it shall not', 'brought to', 'tent and', 'pay your', 'what haste', 'will by', 'shall desire', 'youth and', 'the third', 'custom', 'to sleep', 'did need', 'thee like', 'them and the', 'would change', 'almost with', 'of him that', 'animal']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KovmPnxWDMie",
        "outputId": "b7f07593-64ea-4870-c92e-ff60d62af86e"
      },
      "source": [
        "words=['the', 'and','i','of','my','is','a','he','his','for','d','with']\n",
        "stopwords_dict=dict.fromkeys(words,1)\n",
        "X,y,vocab = createInterestingFeatures(corpus,stopword=True,stem=True,lemma=True,ngram=(1,3),mindf=3,maxdf=2000)\n",
        "runEvaluation(X, y, vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------L1 Norm-----------\n",
            "The model's average accuracy is 0.846154\n",
            "The most informative terms for pos are: ['when some', 'if they can', 'none but', 'attend enter', 'encount', 'soldier no', 'what danger', 'shall our', 'merci in', 'no hope', 'an engin', 'now than', 'differ between', 'respect not', 'time can', 'have got', 'short time', 'thi long', 'in charact', 'all']\n",
            "The most informative terms for neg are: ['which seem', 'will shame', 'help in', 'me gentleman', 'send your', 'ere they', 'in charact', 'an engin', 'shall our', 'differ between', 'thi long', 'time can', 'short time', 'no hope', 'possibl you', 'respect not', 'merci in', 'now than', 'all', 'we on']\n",
            "----------L2 Norm-----------\n",
            "The model's average accuracy is 0.730769\n",
            "The most informative terms for pos are: ['if they can', 'what danger', 'none but', 'attend enter', 'encount', 'soldier no', 'when some', 'am abl', 'night am', 'anoth way', 'shall see', 'it stain', 'have lov', 'left it', 'balanc', 'would that', 'thi glove', 'we are', 'at heart', 'think that had']\n",
            "The most informative terms for neg are: ['which seem', 'will shame', 'help in', 'in mean time', 'sanctuari', 'send your', 'call in', 'writer', 'pitch', 'would we had', 'ere they', 'not cast', 'lord till', 'wherev', 'not poison', 'queen go', 'happi to', 'you took', 'me gentleman', 'matter you']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfTBqBltXe7Y"
      },
      "source": [
        "#given a numpy matrix representation of the features for the training set, the \n",
        "# vector of true classes for each example, and the vocabulary as described \n",
        "# above, this computes the accuracy of the model using leave one out cross \n",
        "# validation and reports the most indicative features for each class\n",
        "def evaluateModel(X,y,vocab,penalty=\"l1\"):\n",
        "  #create and fit the model\n",
        "  model = LogisticRegression(penalty=penalty,solver=\"liblinear\")\n",
        "  results = cross_validate(model,X,y,cv=LeaveOneOut())\n",
        "  \n",
        "  #determine the average accuracy\n",
        "  scores = results[\"test_score\"]\n",
        "  avg_score = sum(scores)/len(scores)\n",
        "  \n",
        "  #determine the most informative features\n",
        "  # this requires us to fit the model to everything, because we need a\n",
        "  # single model to draw coefficients from, rather than 26\n",
        "  model.fit(X,y)\n",
        "  neg_class_prob_sorted = model.coef_[0, :].argsort()\n",
        "  pos_class_prob_sorted = (-model.coef_[0, :]).argsort()\n",
        "\n",
        "  termsToTake = 20\n",
        "  pos_indicators = [vocab[i] for i in neg_class_prob_sorted[:termsToTake]]\n",
        "  neg_indicators = [vocab[i] for i in pos_class_prob_sorted[:termsToTake]]\n",
        "\n",
        "  return avg_score,pos_indicators,neg_indicators\n",
        "\n",
        "def runEvaluation(X,y,vocab):\n",
        "  print(\"----------L1 Norm-----------\")\n",
        "  avg_score,pos_indicators,neg_indicators = evaluateModel(X,y,vocab,\"l1\")\n",
        "  print(\"The model's average accuracy is %f\"%avg_score)\n",
        "  print(\"The most informative terms for pos are: %s\"%pos_indicators)\n",
        "  print(\"The most informative terms for neg are: %s\"%neg_indicators)\n",
        "  #this call will fit a model with L2 normalization\n",
        "  print(\"----------L2 Norm-----------\")\n",
        "  avg_score,pos_indicators,neg_indicators = evaluateModel(X,y,vocab,\"l2\")\n",
        "  print(\"The model's average accuracy is %f\"%avg_score)\n",
        "  print(\"The most informative terms for pos are: %s\"%pos_indicators)\n",
        "  print(\"The most informative terms for neg are: %s\"%neg_indicators)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}